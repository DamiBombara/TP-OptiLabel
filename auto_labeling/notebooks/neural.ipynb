{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "import pygad.cnn\n",
    "import pygad.gacnn\n",
    "import pygad.torchga\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from torchmetrics.classification import Accuracy\n",
    "import matplotlib.pyplot  as plt \n",
    "\n",
    "import numpy as np\n",
    "import pipe  as pp\n",
    "import time\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import auto_labeling.guided as alg\n",
    "sample_shape = (512,512,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining model\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the PyTorch model.\n",
    "input_layer = torch.nn.Conv2d(in_channels=3, out_channels=30, kernel_size=15)\n",
    "relu_layer1 = torch.nn.ReLU()\n",
    "max_pool1   = torch.nn.MaxPool2d(kernel_size=7, stride=5)\n",
    "\n",
    "conv_layer2 = torch.nn.Conv2d(in_channels=30, out_channels=15, kernel_size=11)\n",
    "relu_layer2 = torch.nn.ReLU()\n",
    "\n",
    "conv_layer3 = torch.nn.Conv2d(in_channels=15, out_channels=7, kernel_size=21)\n",
    "relu_layer3 = torch.nn.ReLU()\n",
    "\n",
    "conv_layer4 = torch.nn.Conv2d(in_channels=7, out_channels=5, kernel_size=15)\n",
    "relu_layer4 = torch.nn.ReLU()\n",
    "\n",
    "conv_layer5 = torch.nn.Conv2d(in_channels=5, out_channels=1, kernel_size=3)\n",
    "relu_layer5 = torch.nn.ReLU()\n",
    "\n",
    "flatten_layer1 = torch.nn.Flatten()\n",
    "# The value 100 is pre-computed by tracing the sizes of the layers' outputs.\n",
    "dense_layer1 = torch.nn.Linear(in_features=2809, out_features=100)\n",
    "relu_layer6 = torch.nn.ReLU()\n",
    "\n",
    "dense_layer2 = torch.nn.Linear(in_features=100, out_features=50)\n",
    "relu_layer7 = torch.nn.ReLU()\n",
    "\n",
    "dense_layer3 = torch.nn.Linear(in_features=50, out_features=5)\n",
    "output_layer = torch.nn.Sigmoid()\n",
    "\n",
    "model = torch.nn.Sequential(input_layer,\n",
    "                            relu_layer1,\n",
    "                            max_pool1,\n",
    "                            conv_layer2,\n",
    "                            relu_layer2,\n",
    "                            conv_layer3,\n",
    "                            relu_layer3,\n",
    "                            conv_layer4,\n",
    "                            relu_layer4,\n",
    "                            conv_layer5,\n",
    "                            relu_layer5,\n",
    "                            flatten_layer1,\n",
    "                            dense_layer1,\n",
    "                            relu_layer6,\n",
    "                            dense_layer2,\n",
    "                            relu_layer7,\n",
    "                            dense_layer3,\n",
    "                            output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = torch.nn.Sequential(input_layer,\n",
    "                                 relu_layer1,\n",
    "                                 max_pool1,\n",
    "                                 conv_layer2,\n",
    "                                 relu_layer2,\n",
    "                                 conv_layer3,\n",
    "                                 relu_layer3,\n",
    "                                 conv_layer4,\n",
    "                                 relu_layer4,\n",
    "                                 conv_layer5,\n",
    "                                 relu_layer5,\n",
    "                                 flatten_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten layer output dim: 2809\n"
     ]
    }
   ],
   "source": [
    "# testing how many inputs after convolutions layers do we need\n",
    "torch_ga = pygad.torchga.TorchGA(model=model,\n",
    "                                 num_solutions=1)\n",
    "shp = np.array(torch_ga.population_weights).shape\n",
    "initial_population = list(np.random.rand(*shp))\n",
    "pred = pygad.torchga.predict(model=model_test, solution=initial_population[0], \n",
    "                             data=torch.zeros(sample_shape[2], sample_shape[0], sample_shape[1]))\n",
    "print(f\"Flatten layer output dim: {pred.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of free parameters: 415288\n"
     ]
    }
   ],
   "source": [
    "# testing that our model is correct and lets check amount of parameters\n",
    "pred = pygad.torchga.predict(model=model, solution=initial_population[0], \n",
    "                             data=torch.zeros(sample_shape[2], sample_shape[0], sample_shape[1]))\n",
    "print(f\"Amount of free parameters: {shp[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 30, kernel_size=(15, 15), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=7, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(30, 15, kernel_size=(11, 11), stride=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): Conv2d(15, 7, kernel_size=(21, 21), stride=(1, 1))\n",
      "  (6): ReLU()\n",
      "  (7): Conv2d(7, 5, kernel_size=(15, 15), stride=(1, 1))\n",
      "  (8): ReLU()\n",
      "  (9): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (10): ReLU()\n",
      "  (11): Flatten(start_dim=1, end_dim=-1)\n",
      "  (12): Linear(in_features=2809, out_features=100, bias=True)\n",
      "  (13): ReLU()\n",
      "  (14): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (15): ReLU()\n",
      "  (16): Linear(in_features=50, out_features=5, bias=True)\n",
      "  (17): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preparing data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data automatically basing on shape\n",
    "def load_data(path, shape):\n",
    "    fl_npylike = glob.glob(os.path.join(path, \"*.npy\"))\n",
    "    fl_basenames = list(fl_npylike | pp.map(os.path.basename))\n",
    "\n",
    "    fl_images   = next(fl_basenames | pp.filter(lambda s: \"images\"       in s and f\"{shape[0]}_{shape[1]}\" in s))\n",
    "    fl_gtruth   = next(fl_basenames | pp.filter(lambda s: \"ground_truth\" in s and f\"{shape[0]}_{shape[1]}\" in s))\n",
    "    fl_metadata = next(fl_basenames | pp.filter(lambda s: \"metadata\"     in s and f\"{shape[0]}_{shape[1]}\" in s))\n",
    "    fl_params   = next(fl_basenames | pp.filter(lambda s: \"parameters\"   in s and f\"{shape[0]}_{shape[1]}\" in s))\n",
    "    fl_fitness  = next(fl_basenames | pp.filter(lambda s: \"fitness\"      in s and f\"{shape[0]}_{shape[1]}\" in s))\n",
    "\n",
    "    imgs = np.load(os.path.join(path, fl_images))\n",
    "    imgs_torch   = torch.from_numpy(imgs).permute(0,3,1,2) / 255\n",
    "    #target_torch = torch.from_numpy(np.hstack( [np.load(os.path.join(path, fl_params)), \n",
    "    #                                            np.atleast_2d(np.load(os.path.join(path, fl_fitness))).T] ))\n",
    "    target_torch = torch.from_numpy(np.load(os.path.join(path, fl_params)))\n",
    "    gtruth   = torch.from_numpy(np.load(os.path.join(path, fl_gtruth))) / 255\n",
    "    metadata = np.load(os.path.join(path, fl_metadata))\n",
    "\n",
    "    return imgs, imgs_torch, target_torch, gtruth, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, images_torch, target_torch, gtruth, metadata = load_data(\"../dataset/\", sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# centering and normalizing outputs to use sigmoid layer\n",
    "target_max = target_torch.max(axis=0).values\n",
    "target_min = target_torch.min(axis=0).values\n",
    "target_sigmoid = (target_torch - target_min)/(target_max - target_min)\n",
    "\n",
    "# lets check\n",
    "print(target_sigmoid.max(axis=0).values)\n",
    "print(target_sigmoid.min(axis=0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing images\n",
    "mean = torch.atleast_3d(images_torch.mean(axis=(0, 2, 3))).permute(1, 0, 2)\n",
    "std  = torch.atleast_3d(images_torch.std(axis=(0, 2, 3))).permute(1, 0, 2)\n",
    "images_torch_norm = (images_torch - mean)/std\n",
    "#images_torch_norm = images_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define custom dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, targets):\n",
    "        self.images  = images\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx].float(), self.targets[idx].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(images_torch_norm, target_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning network\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training hyperparameters\n",
    "INIT_LR = 1e-2\n",
    "BATCH_SIZE = 15\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.70\n",
    "VAL_SPLIT   = (1 - TRAIN_SPLIT)/2\n",
    "TEST_SPLIT  = (1 - TRAIN_SPLIT)/2\n",
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrainSamples = int(len(dataset) * TRAIN_SPLIT)\n",
    "numValSamples   = int(len(dataset) * VAL_SPLIT  )\n",
    "numTestSamples  = len(dataset) - numTrainSamples - numValSamples\n",
    "(trainData, valData, testData) = random_split(dataset,\n",
    "\t\t\t\t\t\t\t\t\t          [numTrainSamples, numValSamples, numTestSamples],\n",
    "\t\t\t\t\t\t\t\t\t          generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the train, validation, and test data loaders\n",
    "trainDataLoader = DataLoader(trainData, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valDataLoader   = DataLoader(valData,   batch_size=BATCH_SIZE)\n",
    "testDataLoader  = DataLoader(testData,  batch_size=BATCH_SIZE)\n",
    "\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "valSteps   = len(valDataLoader.dataset)   // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our optimizer and loss function\n",
    "opt = torch.optim.SGD(model.parameters(), lr=INIT_LR)\n",
    "lossFn = torch.nn.L1Loss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"val_loss\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "model.to(device)\n",
    "progress_bar = tqdm(range(0, EPOCHS))\n",
    "# loop over our epochs\n",
    "for e in progress_bar:\n",
    "\t# set the model in training mode\n",
    "\tmodel.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalValLoss = 0\n",
    "\t# initialize the number of correct predictions in the training\n",
    "\t# and validation step\n",
    "\t# loop over the training set\n",
    "\tfor (x, y) in trainDataLoader:\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpred = model(x)\n",
    "\t\tloss = lossFn(pred, y)\n",
    "\t\t# zero out the gradients, perform the backpropagation step,\n",
    "\t\t# and update the weights\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\t\t# add the loss to the total training loss so far\n",
    "\t\ttotalTrainLoss += loss\n",
    "\t\n",
    "\t# switch off autograd for evaluation\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tmodel.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in valDataLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred = model(x)\n",
    "\t\t\ttotalValLoss += lossFn(pred, y)\n",
    "\n",
    "\t# calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgValLoss   = totalValLoss / valSteps\n",
    "\t# update training history\n",
    "\tH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\tH[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "\t# print the model training and validation information\n",
    "\tprogress_bar.set_description(f\"Train loss: {avgTrainLoss:.6f} | Val loss: {avgValLoss:.6f}\")\n",
    "\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TorchScript and save\n",
    "model_scripted = torch.jit.script(model) \n",
    "model_scripted.save('PST_EST_model_scripted_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "torch.save({\n",
    "            'shift': target_min,\n",
    "            'gain': target_max-target_min,\n",
    "            'shape': sample_shape,\n",
    "            'image_mean': mean,\n",
    "            'image_std' : std,\n",
    "            }, \"PST_EST_model_metadata_v1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
